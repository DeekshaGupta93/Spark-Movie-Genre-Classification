{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Intensive Computing- Movie Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4>Overview:</h4> <br>\n",
    "The project demostrates multi-label classification of Movie genre by applying NLP techniques like CountVectorizer, TF-IDF and Word2Vec on plot summaries of the movie.First, the required libraries are imported followed by fetching the train, test and mapping data.\n",
    "Next the data is preprocessed and cleaned by tokenizing \"plot\" column and then stop words are removed from our tokenized terms.\n",
    "Then, features are extracted from the above data frames created using CountVectorizer (for Part 1), TF-IDF (for Part 2) and Word2Vec (for Part 3). \n",
    "Random Forest classifier is used to create a model and attempt to predict the genre of our test data. The multi-label prediction is done in accordance with the format in mapping.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import findspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.functions import split, regexp_replace\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
    "from pyspark.sql.functions import col, udf, lit, explode\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql.functions import when, concat, explode,concat_ws\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, Word2Vec\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.sql.types import StructType, StructField, LongType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Spark Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"myapp\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "sql = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Train, Test and Mapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+--------------------+--------------------+\n",
      "|movie_id|      movie_name|                plot|               genre|\n",
      "+--------+----------------+--------------------+--------------------+\n",
      "|23890098|      Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|\n",
      "|31186339|The Hunger Games|The nation of Pan...|['Action/Adventur...|\n",
      "+--------+----------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|\n",
      "+--------+--------------------+--------------------+\n",
      "| 1335380|              Exodus|The film is based...|\n",
      "|29062594|A la salida nos v...|A group of teenag...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+------+\n",
      "|Unnamed: 0|     0|\n",
      "+----------+------+\n",
      "|         0| Drama|\n",
      "|         1|Comedy|\n",
      "+----------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "traindata = pd.read_csv(\"train.csv\")\n",
    "train_data = sql.createDataFrame(traindata)\n",
    "train_data.show(2)\n",
    "\n",
    "# Test Data\n",
    "testdata = pd.read_csv(\"test.csv\")\n",
    "test_data = sql.createDataFrame(testdata)\n",
    "test_data.show(2)\n",
    "\n",
    "# Mapping Data\n",
    "mappingdata = pd.read_csv(\"mapping.csv\")\n",
    "mapping_data = sql.createDataFrame(mappingdata)\n",
    "mapping_data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have fetched the Genre mapping data and stored the index-genre pair as the key-value pair in a dictionary\n",
    "# We will use this later on when we train our data on 20 classifiers\n",
    "\n",
    "mapping_data = (mapping_data.withColumnRenamed(\"Unnamed: 0\",\"ID\").withColumnRenamed(\"0\",\"Genre\")).collect()\n",
    "map_dictionary = {}\n",
    "for i in range(0,20):\n",
    "    map_dictionary[i] = mapping_data[i]['Genre'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: RegexTokenizer and StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(inputCol=\"plot\", outputCol=\"tokenizedterms\")\n",
    "# train_df2 = tokenizer.transform(train_df1).head(31108)\n",
    "\n",
    "rt = RegexTokenizer(inputCol = \"plot\", outputCol = \"tokenized_terms\", pattern = \"\\\\W\")\n",
    "train_df = rt.transform(train_data)\n",
    "test_df = rt.transform(test_data)\n",
    "\n",
    "swr = StopWordsRemover(inputCol = \"tokenized_terms\", outputCol = \"updated_terms\")\n",
    "train_df = swr.transform(train_df)\n",
    "test_df = swr.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('tokenized_terms')\n",
    "test_df = test_df.drop('tokenized_terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = train_df\n",
    "train_df2 = train_df\n",
    "train_df3 = train_df\n",
    "test_df1 = test_df\n",
    "test_df2 = test_df\n",
    "test_df3 = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pd.read_csv(\"/home/cse587/dic487-587/mapping.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Term Document Matrix (Count Vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|        movie_name|                plot|               genre|       updated_terms|            features|\n",
      "+--------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|23890098|        Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[shlykov, hard, w...|(9000,[10,129,186...|\n",
      "|31186339|  The Hunger Games|The nation of Pan...|['Action/Adventur...|[nation, panem, c...|(9000,[2,6,7,10,1...|\n",
      "|20663735|        Narasimham|Poovalli Induchoo...|['Musical', 'Acti...|[poovalli, induch...|(9000,[1,3,8,10,1...|\n",
      "| 2231378|The Lemon Drop Kid|The Lemon Drop Ki...|          ['Comedy']|[lemon, drop, kid...|(9000,[7,9,12,15,...|\n",
      "|  595909| A Cry in the Dark|Seventh-day Adven...|['Crime Fiction',...|[seventh, day, ad...|(9000,[2,8,9,14,1...|\n",
      "+--------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|       updated_terms|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 1335380|              Exodus|The film is based...|[film, based, eve...|(9000,[0,3,6,7,8,...|\n",
      "|29062594|A la salida nos v...|A group of teenag...|[group, teenagers...|(9000,[7,12,56,67...|\n",
      "| 9252321|   Come Back, Africa|This story of a Z...|[story, zulu, fam...|(9000,[4,7,8,10,1...|\n",
      "|13455076|       A Merry Mixup|The Stooges play ...|[stooges, play, t...|(9000,[0,76,78,79...|\n",
      "|24165951|        Getting Even|A soldier-of-fort...|[soldier, fortune...|(9000,[19,392,439...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Count Vectorizer over our train and test data\n",
    "cv = CountVectorizer(inputCol = \"updated_terms\", outputCol = \"features\", vocabSize = 9000, minDF = 8)\n",
    "model = cv.fit(train_df1)\n",
    "train_df1 = model.transform(train_df1)\n",
    "train_df1.show(n = 5)\n",
    "\n",
    "model = cv.fit(test_df1)\n",
    "test_df1 = model.transform(test_df1)\n",
    "test_df1.show(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|movie_id|movie_name|                plot|               genre|       updated_terms|            features|multiLabels|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|23890098|Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[shlykov, hard, w...|(9000,[10,129,186...|        4.0|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start of Random Forest Implementation\n",
    "str_ind = StringIndexer(inputCol = \"genre\", outputCol = \"multiLabels\")\n",
    "model = str_ind.fit(train_df1)\n",
    "train_df1 = model.transform(train_df1)\n",
    "train_df1.show(n=1)\n",
    "u_labels = model.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(labelCol=\"multiLabels\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 10, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 10)\n",
    "# Train model with Training Data\n",
    "train_Model = rfc_model.fit(train_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Index to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_id',\n",
       " 'movie_name',\n",
       " 'plot',\n",
       " 'updated_terms',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction',\n",
       " 'ClassLabel']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1 = train_Model.transform(test_df1)\n",
    "ind_to_str = IndexToString(inputCol=\"prediction\", outputCol=\"ClassLabel\", labels = u_labels)\n",
    "test_result = ind_to_str.transform(test_pred1)\n",
    "test_result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String to 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29162674', '1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']\n"
     ]
    }
   ],
   "source": [
    "result_values = test_result.select('movie_id','ClassLabel').collect()\n",
    "result = [['movie_id','predictions']]\n",
    "for idx,i in enumerate(result_values):\n",
    "#     print(''.join(str([1 if x[0]==i else 0 for x in mapping_df.values])))\n",
    "    cats = str(i['ClassLabel']).split(',')\n",
    "    cats = [x.strip(\"[]\\'' \") for x in cats]\n",
    "    val = ''.join(map(str,[str(1)+' ' if x[0] in cats else str(0)+' ' for x in mapping_df.values]))\n",
    "    result.append([str(i['movie_id']),val.strip(' ')])\n",
    "print(result[5983])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result)\n",
    "result.to_csv('rf1.csv',index = False, header = False) #Saving the csv file to our local folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashTF_init = HashingTF(inputCol = \"updated_terms\", outputCol = \"rawfeatures\", numFeatures = 10000)\n",
    "hashtrain_transform = hashTF_init.transform(train_df2)\n",
    "idftrain = IDF(inputCol = \"rawfeatures\", outputCol = \"features\")\n",
    "idftrain_fit = idftrain.fit(hashtrain_transform)\n",
    "train_df2 = idftrain_fit.transform(hashtrain_transform)\n",
    "\n",
    "#hashTF_init = HashingTF(inputCol=\"updatedterms\", outputCol=\"rawfeatures\", numFeatures=9000)\n",
    "hashtest_transform = hashTF_init.transform(test_df2)\n",
    "idftest = IDF(inputCol = \"rawfeatures\", outputCol = \"features\")\n",
    "idftest_fit = idftest.fit(hashtest_transform)\n",
    "test_df2 = idftest_fit.transform(hashtest_transform)\n",
    "\n",
    "# While creating TF - IDF we have to make sure that both the train and test data have the same number of features.\n",
    "# This is because if they aren't the same then Naives Bayes returns a dimension mismatch error while creating the\n",
    "# model and predicting the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|movie_id|movie_name|                plot|               genre|       updated_terms|         rawfeatures|            features|multiLabels|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|23890098|Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[shlykov, hard, w...|(10000,[135,719,1...|(10000,[135,719,1...|        4.0|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start of Random Forest Implementation\n",
    "str_ind = StringIndexer(inputCol = \"genre\", outputCol = \"multiLabels\")\n",
    "model = str_ind.fit(train_df2)\n",
    "train_df2 = model.transform(train_df2)\n",
    "train_df2.show(n=1)\n",
    "u_labels = model.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(labelCol=\"multiLabels\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 10, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 10)\n",
    "# Train model with Training Data\n",
    "train_Model = rfc_model.fit(train_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Index to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_id',\n",
       " 'movie_name',\n",
       " 'plot',\n",
       " 'updated_terms',\n",
       " 'rawfeatures',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction',\n",
       " 'ClassLabel']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2 = train_Model.transform(test_df2)\n",
    "ind_to_str = IndexToString(inputCol=\"prediction\", outputCol=\"ClassLabel\", labels = u_labels)\n",
    "test_result = ind_to_str.transform(test_pred2)\n",
    "test_result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String to 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29162674', '1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']\n"
     ]
    }
   ],
   "source": [
    "result_values = test_result.select('movie_id','ClassLabel').collect()\n",
    "result = [['movie_id','predictions']]\n",
    "for idx,i in enumerate(result_values):\n",
    "#     print(''.join(str([1 if x[0]==i else 0 for x in mapping_df.values])))\n",
    "    cats = str(i['ClassLabel']).split(',')\n",
    "    cats = [x.strip(\"[]\\'' \") for x in cats]\n",
    "    val = ''.join(map(str,[str(1)+' ' if x[0] in cats else str(0)+' ' for x in mapping_df.values]))\n",
    "    result.append([str(i['movie_id']),val.strip(' ')])\n",
    "print(result[5983])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result)\n",
    "result.to_csv('rf2.csv',index = False,header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(vectorSize = 300, minCount = 10, inputCol = 'updated_terms', outputCol = 'features')\n",
    "word2vec_transform = word2vec.fit(train_df3)\n",
    "train_df3 = word2vec_transform.transform(train_df3)\n",
    "\n",
    "word2vec = Word2Vec(vectorSize = 250, minCount = 5, inputCol = 'updated_terms', outputCol = 'vectors')\n",
    "word2vec_transform = word2vec.fit(test_df3)\n",
    "test_df3 = word2vec_transform.transform(test_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|movie_id|movie_name|                plot|               genre|       updated_terms|            features|multiLabels|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|23890098|Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[shlykov, hard, w...|[-0.0112350715652...|        4.0|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start of Random Forest Implementation\n",
    "str_ind = StringIndexer(inputCol = \"genre\", outputCol = \"multiLabels\")\n",
    "model = str_ind.fit(train_df3)\n",
    "train_df3 = model.transform(train_df3)\n",
    "train_df3.show(n=1)\n",
    "u_labels = model.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(labelCol=\"multiLabels\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 10, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 10)\n",
    "# Train model with Training Data\n",
    "train_Model = rfc_model.fit(train_df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Index to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_id',\n",
       " 'movie_name',\n",
       " 'plot',\n",
       " 'genre',\n",
       " 'updated_terms',\n",
       " 'features',\n",
       " 'multiLabels',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction',\n",
       " 'ClassLabel']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred3 = train_Model.transform(train_df3)\n",
    "ind_to_str = IndexToString(inputCol=\"prediction\", outputCol=\"ClassLabel\", labels = u_labels)\n",
    "test_result = ind_to_str.transform(test_pred3)\n",
    "test_result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String to 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1716921', '1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']\n"
     ]
    }
   ],
   "source": [
    "result_values = test_result.select('movie_id','ClassLabel').collect()\n",
    "result = [['movie_id','predictions']]\n",
    "for idx,i in enumerate(result_values):\n",
    "#     print(''.join(str([1 if x[0]==i else 0 for x in mapping_df.values])))\n",
    "    cats = str(i['ClassLabel']).split(',')\n",
    "    cats = [x.strip(\"[]\\'' \") for x in cats]\n",
    "    val = ''.join(map(str,[str(1)+' ' if x[0] in cats else str(0)+' ' for x in mapping_df.values]))\n",
    "    result.append([str(i['movie_id']),val.strip(' ')])\n",
    "print(result[5983])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result)\n",
    "result.to_csv('rf3.csv',index = False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
